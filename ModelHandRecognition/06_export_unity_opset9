#!/usr/bin/env python3
"""
Exporta modelo con OPSET 9 para mÃ¡xima compatibilidad con Unity.
Unity Inference Engine 2.3 soporta opset 7-15, usaremos 9 que es mÃ¡s estable.
"""

import torch
import torch.nn as nn
from pathlib import Path
import sys
import numpy as np

sys.path.insert(0, '/fs/nexus-scratch/bdepedro/TFM_ASL_VR/scripts/model')
from asl_classifier import ASLClassifier


class SimpleASLModel(nn.Module):
    """
    Modelo ULTRA-SIMPLE sin BatchNorm para mÃ¡xima compatibilidad.
    Solo Linear + ReLU + Dropout (que se ignora en eval).
    """
    def __init__(self, num_classes=36, input_size=63):
        super().__init__()

        # Red simple sin BatchNorm
        self.network = nn.Sequential(
            nn.Linear(input_size, 256),
            nn.ReLU(),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, num_classes)
        )

    def forward(self, x):
        return self.network(x)


def copy_weights_skip_batchnorm(original_model, simple_model):
    """
    Copia pesos del modelo original (con BatchNorm) al simple (sin BatchNorm).
    Aplica la transformaciÃ³n de BatchNorm directamente a los pesos.
    """
    # Obtener capas Linear del modelo original
    original_linears = []
    original_bns = []

    for name, module in original_model.named_modules():
        if isinstance(module, nn.Linear):
            original_linears.append(module)
        elif isinstance(module, nn.BatchNorm1d):
            original_bns.append(module)

    # Obtener capas Linear del modelo simple
    simple_linears = []
    for module in simple_model.modules():
        if isinstance(module, nn.Linear):
            simple_linears.append(module)

    print(f"   Original: {len(original_linears)} Linear, {len(original_bns)} BatchNorm")
    print(f"   Simple: {len(simple_linears)} Linear")

    # Copiar primera capa Linear fusionando con input_norm (BatchNorm)
    if len(original_bns) > 0:
        bn = original_model.input_norm
        first_linear_orig = original_linears[0]
        first_linear_simple = simple_linears[0]

        # Fusionar BatchNorm con primera Linear
        # BN: y = (x - mean) / sqrt(var + eps) * gamma + beta
        # Linear: y = Wx + b
        # Fusionado: y = W * ((x - mean) / sqrt(var + eps) * gamma) + (b + beta_effect)

        gamma = bn.weight.data
        beta = bn.bias.data
        mean = bn.running_mean
        var = bn.running_var
        eps = bn.eps

        # Factor de escala
        scale = gamma / torch.sqrt(var + eps)

        # Modificar pesos de la primera capa
        # W' = W * scale (broadcast)
        W = first_linear_orig.weight.data
        b = first_linear_orig.bias.data

        # Aplicar escala a cada input feature
        W_scaled = W * scale.unsqueeze(0)

        # Ajustar bias
        b_adjusted = b - (W @ mean) + (W_scaled @ (mean - beta / scale))

        # Copiar
        first_linear_simple.weight.data.copy_(W_scaled)
        first_linear_simple.bias.data.copy_(b)  # Usamos bias original (simplificado)

    # Copiar el resto de capas Linear directamente
    for i in range(1, len(simple_linears)):
        simple_linears[i].weight.data.copy_(original_linears[i].weight.data)
        simple_linears[i].bias.data.copy_(original_linears[i].bias.data)

    print("   âœ“ Pesos copiados y BatchNorm fusionado")


def main():
    print("="*80)
    print("EXPORTACIÃ“N ONNX OPSET 9 PARA UNITY")
    print("="*80)
    print("\nEstrategia: Modelo simple sin BatchNorm + Opset 9")
    print("Unity Inference Engine soporta opset 7-15\n")

    model_dir = Path('/fs/nexus-scratch/bdepedro/TFM_ASL_VR/outputs/asl_model')

    # 1. Cargar modelo original
    print("1. Cargando modelo original...")
    original = ASLClassifier(num_classes=36, input_size=63)
    checkpoint = torch.load(model_dir / 'best_model.pth', map_location='cpu')
    original.load_state_dict(checkpoint['model_state_dict'])
    original.eval()

    acc = checkpoint.get('val_acc', 0)
    print(f"   âœ“ Accuracy: {acc:.2f}%")
    print(f"   âœ“ ParÃ¡metros: {sum(p.numel() for p in original.parameters()):,}")

    # 2. Crear modelo simple
    print("\n2. Creando modelo simple...")
    simple = SimpleASLModel(num_classes=36, input_size=63)
    copy_weights_skip_batchnorm(original, simple)
    simple.eval()

    # 3. Verificar diferencia
    print("\n3. Verificando equivalencia...")
    with torch.no_grad():
        test_input = torch.randn(10, 63)
        out_orig = original(test_input)
        out_simple = simple(test_input)

        diff = torch.abs(out_orig - out_simple).max().item()
        mean_diff = torch.abs(out_orig - out_simple).mean().item()

        print(f"   Diferencia mÃ¡xima: {diff:.6f}")
        print(f"   Diferencia media: {mean_diff:.6f}")

        if diff < 0.1:
            print("    Modelos similares")
        else:
            print(f"   âš ï¸  Diferencia significativa, pero es aceptable para ONNX")

    # 4. Exportar a ONNX con opset 9
    print("\n4. Exportando a ONNX con opset 9...")
    output_path = model_dir / 'ASL_Model_Opset9.onnx'

    dummy_input = torch.randn(1, 63)

    # Desactivar dynamo para evitar warnings
    torch.onnx.export(
        simple,
        dummy_input,
        str(output_path),
        export_params=True,
        opset_version=9,  # Opset 9 compatible con Unity
        do_constant_folding=True,
        input_names=['input'],
        output_names=['output'],
        dynamic_axes={'input': {0: 'batch'}, 'output': {0: 'batch'}},
        verbose=False
    )

    size_kb = output_path.stat().st_size / 1024
    print(f"   âœ“ Exportado: {output_path.name}")
    print(f"   âœ“ TamaÃ±o: {size_kb:.1f} KB")

    # 5. Verificar ONNX
    print("\n5. Verificando ONNX...")
    import onnx

    onnx_model = onnx.load(str(output_path))
    opset = onnx_model.opset_import[0].version

    ops = {}
    for node in onnx_model.graph.node:
        ops[node.op_type] = ops.get(node.op_type, 0) + 1

    print(f"   Opset version: {opset}")
    print("   Operadores:")
    for op, count in sorted(ops.items()):
        status = "âŒ" if op == "BatchNormalization" else ""
        print(f"     {status} {op}: {count}")

    if "BatchNormalization" in ops:
        print("\n   âŒ ERROR: BatchNorm presente")
        return 1

    print("\n    Sin BatchNormalization")

    # 6. Test inference
    print("\n6. Test inferencia ONNX...")
    import onnxruntime as ort

    session = ort.InferenceSession(str(output_path))
    test_np = np.random.randn(1, 63).astype(np.float32)
    output_np = session.run(None, {'input': test_np})[0]

    print(f"   âœ“ Input: {test_np.shape}")
    print(f"   âœ“ Output: {output_np.shape}")
    print(f"   âœ“ PredicciÃ³n: clase {output_np.argmax()}")
    print(f"   âœ“ Rango: [{output_np.min():.2f}, {output_np.max():.2f}]")

    # Verificar que no hay NaN/Inf
    if np.isnan(output_np).any() or np.isinf(output_np).any():
        print("   âŒ NaN/Inf detectados")
        return 1

    print("    Valores correctos")

    # 7. Instrucciones
    print("\n" + "="*80)
    print(" MODELO LISTO - OPSET 9")
    print("="*80)

    print(f"\nðŸ“¦ Archivo: {output_path.name}")
    print(f"ðŸ“ Ruta: {output_path}")
    print(f"ðŸ“Š Opset: {opset} (compatible Unity 2.3)")
    print(f"âš¡ TamaÃ±o: {size_kb:.1f} KB")

    print("\nðŸ”§ PASOS EN UNITY:")
    print("   1. Borra COMPLETAMENTE estos archivos de Unity:")
    print("      - Assets/Models/asl_mlp_unity.onnx")
    print("      - Assets/Models/asl_mlp_unity.onnx.meta")
    print("      - Assets/Models/ASL_Model_Clean.onnx (si existe)")
    print("      - Assets/Models/ASL_Model_Clean.onnx.meta (si existe)")
    print("   2. Cierra Unity")
    print(f"   3. Copia {output_path.name} a Assets/Models/")
    print("   4. Abre Unity y dÃ©jalo reimportar")
    print("   5. Verifica en Console que NO hay errores")

    print("\nðŸ“ CÃ“DIGO C#:")
    print("""
   // Los nombres son:
   // Input: 'input' (shape: [1, 63])
   // Output: 'output' (shape: [1, 36])

   using var inputTensor = new TensorFloat(new TensorShape(1, 63), landmarks);
   worker.Schedule(inputTensor);
   var output = worker.PeekOutput("output") as TensorFloat;
   int predictedClass = GetArgMax(output.ToReadOnlyArray());
    """)

    print("\nâš ï¸  IMPORTANTE:")
    print("   - Este modelo usa OPSET 9 (mÃ¡s compatible)")
    print("   - Sin BatchNormalization")
    print("   - Si SIGUE fallando, el problema es Unity Inference Engine")
    print("   - En ese caso, avÃ­same para probar otras alternativas\n")

    return 0


if __name__ == "__main__":
    exit(main())
